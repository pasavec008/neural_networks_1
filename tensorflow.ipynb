{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHITECTURE = 'FFNN'\n",
    "WANDB_API_KEY = '5fed3be7a2bb71354e65254cba73f68f903cc854'\n",
    "CONF_INDEX = 13\n",
    "CONF = {\n",
    "    'lr': [0.001, 0.00001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
    "    'num_epochs': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
    "    'gamma': [0.05, 0.05, 0.5, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.25],\n",
    "    'scheduler_step_size': [20, 20, 20, 50, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
    "    'batch_size': [32, 32, 32, 32, 128, 32, 32, 32, 32, 32, 32, 32, 32, 64],\n",
    "    'run_name': [\n",
    "        'Case 1',\n",
    "        'Case 2',\n",
    "        'Case 3',\n",
    "        'Case 4',\n",
    "        'Case 5',\n",
    "        'Case 6',\n",
    "        'Case 7',\n",
    "        'Case 8',\n",
    "        'Case 9',\n",
    "        'Case 10',\n",
    "        'Case 11',\n",
    "        'Case 12',\n",
    "        'Case 13',\n",
    "        'Case 14',\n",
    "    ],\n",
    "    'nn_size': [\n",
    "        'medium_wide',\n",
    "        'medium_wide',\n",
    "        'medium_wide',\n",
    "        'medium_wide',\n",
    "        'medium_wide',\n",
    "        'small',\n",
    "        'large',\n",
    "        'medium_wide',\n",
    "        'medium_wide',\n",
    "        'medium_wide',\n",
    "        'medium_wide',\n",
    "        'medium_wide',\n",
    "        'medium_wide',\n",
    "        'large',\n",
    "    ],\n",
    "    'act_func': [\n",
    "        'leaky_relu',\n",
    "        'leaky_relu',\n",
    "        'leaky_relu',\n",
    "        'leaky_relu',\n",
    "        'leaky_relu',\n",
    "        'leaky_relu',\n",
    "        'leaky_relu',\n",
    "        'relu',\n",
    "        'tanh',\n",
    "        'sigmoid',\n",
    "        'leaky_relu',\n",
    "        'leaky_relu',\n",
    "        'leaky_relu',\n",
    "        'relu',\n",
    "    ],\n",
    "    'loss_func': [\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'hubert',\n",
    "        'mse',\n",
    "        'mse',\n",
    "        'hubert',\n",
    "    ],\n",
    "    'optimizers': [\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'sgd',\n",
    "        'rmsprop',\n",
    "        'adam',\n",
    "        'rmsprop',\n",
    "    ]\n",
    "}\n",
    "\n",
    "act_functions = {\n",
    "    'leaky_relu': tf.keras.layers.LeakyReLU(alpha=0.01),\n",
    "    'relu': 'relu',\n",
    "    'tanh': 'tanh',\n",
    "    'sigmoid': 'sigmoid',\n",
    "}\n",
    "\n",
    "loss_functions = {\n",
    "    'mse': 'mse',\n",
    "    'hubert': 'huber', # risk\n",
    "}\n",
    "\n",
    "optimizers = {\n",
    "    'sgd': tf.keras.optimizers.SGD(learning_rate=CONF['lr'][CONF_INDEX] / 10),\n",
    "    'rmsprop': tf.keras.optimizers.RMSprop(learning_rate=CONF['lr'][CONF_INDEX] / 10),\n",
    "    'adam': tf.keras.optimizers.Adam(learning_rate=CONF['lr'][CONF_INDEX] / 10),\n",
    "}\n",
    "\n",
    "NAME = CONF['run_name'][CONF_INDEX]\n",
    "LEARNING_RATE = CONF['lr'][CONF_INDEX] / 10\n",
    "NUM_EPOCHS = CONF['num_epochs'][CONF_INDEX]\n",
    "GAMMA = CONF['gamma'][CONF_INDEX]\n",
    "SCHEDULER_STEP_SIZE = CONF['scheduler_step_size'][CONF_INDEX]\n",
    "BATCH_SIZE = CONF['batch_size'][CONF_INDEX]\n",
    "NN_SIZE = CONF['nn_size'][CONF_INDEX]\n",
    "ACT_FUNC = act_functions[CONF['act_func'][CONF_INDEX]]\n",
    "LOSS_FUNC = loss_functions[CONF['loss_func'][CONF_INDEX]]\n",
    "OPTIMIZER_FUNCT = optimizers[CONF['optimizers'][CONF_INDEX]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ejbdw4mz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_r2</td><td>▁▅▇█████████████████████████████████████</td></tr><tr><td>basic_accuracy</td><td>▁▂▆▇▇▇██████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_r2</td><td>0.17324</td></tr><tr><td>basic_accuracy</td><td>0.51462</td></tr><tr><td>train_loss</td><td>0.59597</td></tr><tr><td>val_loss</td><td>0.63121</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Case 13</strong> at: <a href='https://wandb.ai/adamovic-kubicka/nn_tensorflow/runs/ejbdw4mz' target=\"_blank\">https://wandb.ai/adamovic-kubicka/nn_tensorflow/runs/ejbdw4mz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230329_195445-ejbdw4mz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ejbdw4mz). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/oliverkubicka/Desktop/FIIT/NSIETE/neural_networks_1/wandb/run-20230329_195601-mczzo9hp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamovic-kubicka/nn_tensorflow/runs/mczzo9hp' target=\"_blank\">Case 14</a></strong> to <a href='https://wandb.ai/adamovic-kubicka/nn_tensorflow' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamovic-kubicka/nn_tensorflow' target=\"_blank\">https://wandb.ai/adamovic-kubicka/nn_tensorflow</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamovic-kubicka/nn_tensorflow/runs/mczzo9hp' target=\"_blank\">https://wandb.ai/adamovic-kubicka/nn_tensorflow/runs/mczzo9hp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/adamovic-kubicka/nn_tensorflow/runs/mczzo9hp?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f927b82df60>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "wandb.init(\n",
    "    project='nn_tensorflow',\n",
    "    name=NAME,\n",
    "    config={\n",
    "        'dataset': 'wines',\n",
    "        'architecture': ARCHITECTURE,\n",
    "        'nn_size': NN_SIZE,\n",
    "        'act_func': ACT_FUNC,\n",
    "        'loss_func': LOSS_FUNC,\n",
    "        'optimizer_func': OPTIMIZER_FUNCT,\n",
    "        'LR': LEARNING_RATE,\n",
    "        'gamma': GAMMA,\n",
    "        'step_size': SCHEDULER_STEP_SIZE,\n",
    "        'epochs': NUM_EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "5            8.1              0.28         0.40             6.9      0.050   \n",
       "6            6.2              0.32         0.16             7.0      0.045   \n",
       "7            7.0              0.27         0.36            20.7      0.045   \n",
       "8            6.3              0.30         0.34             1.6      0.049   \n",
       "9            8.1              0.22         0.43             1.5      0.044   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "5                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "6                 30.0                 136.0   0.9949  3.18       0.47   \n",
       "7                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "8                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "9                 28.0                 129.0   0.9938  3.22       0.45   \n",
       "\n",
       "   alcohol  quality  color  \n",
       "0      8.8        6      0  \n",
       "1      9.5        6      0  \n",
       "2     10.1        6      0  \n",
       "3      9.9        6      0  \n",
       "4      9.9        6      0  \n",
       "5     10.1        6      0  \n",
       "6      9.6        6      0  \n",
       "7      8.8        6      0  \n",
       "8      9.5        6      0  \n",
       "9     11.0        6      0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cleaned_data.csv', delimiter = ';')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (5197, 12) (5197,)\n",
      "Testing set shape: (1300, 12) (1300,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = df.drop('quality', axis=1)  # Features\n",
    "y = df['quality']               # Target variable\n",
    "\n",
    "# We use stratify on y so we get same wine quality distribution in test and train dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27, stratify = y)\n",
    "\n",
    "print('Training set shape:', X_train.shape, y_train.shape)\n",
    "print('Testing set shape:', X_test.shape, y_test.shape)\n",
    "\n",
    "# transform data to correct type\n",
    "X_train, X_test = X_train.values, X_test.values\n",
    "y_train, y_test = y_train.values, y_test.values\n",
    "print(type(X_train), type(y_train), type(X_test), type(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network architecture\n",
    "\n",
    "- Number of inputs for first layer is same as the number of attributes (columns) in our dataset\n",
    "- Number of outputs in last layer needs to be equal to the number of values that network is expected to predict. In our case we are trying to predict wine quality (range <3,9>)\n",
    "- The number of neurons (inputs and outputs) per layer in hidden layers can vary - we need to try different values to find better network performace. A good rule of thumb is to start with a smaller number of neurons and gradually increase the number of neurons until you find the optimal number that gives you the best performance.\n",
    "- We choose **ReLU as actiovation function**. In general, it works well\n",
    "- MSELoss (Mean squared error) is commonly use when you want to penalize larger errors more than smaller ones (common choise for regression problems)\n",
    "- We choose **SGD optimizer** because we have small dataset and problem with small complexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architectures\n",
    "model = None\n",
    "if NN_SIZE == 'small':\n",
    "    model = keras.Sequential([\n",
    "        tf.keras.layers.Dense(8, activation=ACT_FUNC, input_shape=(12,)),\n",
    "        tf.keras.layers.Dense(4, activation=ACT_FUNC),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "elif NN_SIZE == 'medium_wide':\n",
    "    model = keras.Sequential([\n",
    "        tf.keras.layers.Dense(15, activation=ACT_FUNC, input_shape=(12,)),\n",
    "        tf.keras.layers.Dense(33, activation=ACT_FUNC),\n",
    "        tf.keras.layers.Dense(16, activation=ACT_FUNC),\n",
    "        tf.keras.layers.Dense(13, activation=ACT_FUNC),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "elif NN_SIZE == 'large':\n",
    "    model = keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation=ACT_FUNC, input_shape=(12,)),\n",
    "        tf.keras.layers.Dense(54, activation=ACT_FUNC),\n",
    "        tf.keras.layers.Dense(33, activation=ACT_FUNC),\n",
    "        tf.keras.layers.Dense(72, activation=ACT_FUNC),\n",
    "        tf.keras.layers.Dense(50, activation=ACT_FUNC),\n",
    "        tf.keras.layers.Dense(110, activation=ACT_FUNC),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 733us/step\n",
      "41/41 [==============================] - 0s 714us/step\n",
      "41/41 [==============================] - 0s 662us/step\n",
      "41/41 [==============================] - 0s 628us/step\n",
      "41/41 [==============================] - 0s 693us/step\n",
      "41/41 [==============================] - 0s 684us/step\n",
      "41/41 [==============================] - 0s 665us/step\n",
      "41/41 [==============================] - 0s 680us/step\n",
      "41/41 [==============================] - 0s 685us/step\n",
      "41/41 [==============================] - 0s 605us/step\n",
      "41/41 [==============================] - 0s 691us/step\n",
      "41/41 [==============================] - 0s 694us/step\n",
      "41/41 [==============================] - 0s 705us/step\n",
      "41/41 [==============================] - 0s 686us/step\n",
      "41/41 [==============================] - 0s 614us/step\n",
      "41/41 [==============================] - 0s 672us/step\n",
      "41/41 [==============================] - 0s 607us/step\n",
      "41/41 [==============================] - 0s 715us/step\n",
      "41/41 [==============================] - 0s 698us/step\n",
      "41/41 [==============================] - 0s 693us/step\n",
      "41/41 [==============================] - 0s 618us/step\n",
      "41/41 [==============================] - 0s 611us/step\n",
      "41/41 [==============================] - 0s 673us/step\n",
      "41/41 [==============================] - 0s 599us/step\n",
      "41/41 [==============================] - 0s 620us/step\n",
      "41/41 [==============================] - 0s 676us/step\n",
      "41/41 [==============================] - 0s 700us/step\n",
      "41/41 [==============================] - 0s 649us/step\n",
      "41/41 [==============================] - 0s 708us/step\n",
      "41/41 [==============================] - 0s 584us/step\n",
      "41/41 [==============================] - 0s 621us/step\n",
      "41/41 [==============================] - 0s 650us/step\n",
      "41/41 [==============================] - 0s 681us/step\n",
      "41/41 [==============================] - 0s 669us/step\n",
      "41/41 [==============================] - 0s 701us/step\n",
      "41/41 [==============================] - 0s 619us/step\n",
      "41/41 [==============================] - 0s 680us/step\n",
      "41/41 [==============================] - 0s 653us/step\n",
      "41/41 [==============================] - 0s 696us/step\n",
      "41/41 [==============================] - 0s 665us/step\n",
      "41/41 [==============================] - 0s 700us/step\n",
      "41/41 [==============================] - 0s 675us/step\n",
      "41/41 [==============================] - 0s 688us/step\n",
      "41/41 [==============================] - 0s 648us/step\n",
      "41/41 [==============================] - 0s 637us/step\n",
      "41/41 [==============================] - 0s 650us/step\n",
      "41/41 [==============================] - 0s 632us/step\n",
      "41/41 [==============================] - 0s 621us/step\n",
      "41/41 [==============================] - 0s 630us/step\n",
      "41/41 [==============================] - 0s 625us/step\n",
      "41/41 [==============================] - 0s 700us/step\n",
      "41/41 [==============================] - 0s 718us/step\n",
      "41/41 [==============================] - 0s 719us/step\n",
      "41/41 [==============================] - 0s 693us/step\n",
      "41/41 [==============================] - 0s 692us/step\n",
      "41/41 [==============================] - 0s 714us/step\n",
      "41/41 [==============================] - 0s 711us/step\n",
      "41/41 [==============================] - 0s 657us/step\n",
      "41/41 [==============================] - 0s 701us/step\n",
      "41/41 [==============================] - 0s 723us/step\n",
      "41/41 [==============================] - 0s 625us/step\n",
      "41/41 [==============================] - 0s 643us/step\n",
      "41/41 [==============================] - 0s 708us/step\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "41/41 [==============================] - 0s 684us/step\n",
      "41/41 [==============================] - 0s 683us/step\n",
      "41/41 [==============================] - 0s 739us/step\n",
      "41/41 [==============================] - 0s 649us/step\n",
      "41/41 [==============================] - 0s 708us/step\n",
      "41/41 [==============================] - 0s 675us/step\n",
      "41/41 [==============================] - 0s 738us/step\n",
      "41/41 [==============================] - 0s 611us/step\n",
      "41/41 [==============================] - 0s 629us/step\n",
      "41/41 [==============================] - 0s 645us/step\n",
      "41/41 [==============================] - 0s 792us/step\n",
      "41/41 [==============================] - 0s 693us/step\n",
      "41/41 [==============================] - 0s 709us/step\n",
      "41/41 [==============================] - 0s 689us/step\n",
      "41/41 [==============================] - 0s 692us/step\n",
      "41/41 [==============================] - 0s 629us/step\n",
      "41/41 [==============================] - 0s 619us/step\n",
      "41/41 [==============================] - 0s 610us/step\n",
      "41/41 [==============================] - 0s 624us/step\n",
      "41/41 [==============================] - 0s 595us/step\n",
      "41/41 [==============================] - 0s 707us/step\n",
      "41/41 [==============================] - 0s 692us/step\n",
      "41/41 [==============================] - 0s 664us/step\n",
      "41/41 [==============================] - 0s 583us/step\n",
      "41/41 [==============================] - 0s 586us/step\n",
      "41/41 [==============================] - 0s 588us/step\n",
      "41/41 [==============================] - 0s 631us/step\n",
      "41/41 [==============================] - 0s 704us/step\n",
      "41/41 [==============================] - 0s 595us/step\n",
      "41/41 [==============================] - 0s 612us/step\n",
      "41/41 [==============================] - 0s 620us/step\n",
      "41/41 [==============================] - 0s 596us/step\n",
      "41/41 [==============================] - 0s 614us/step\n",
      "41/41 [==============================] - 0s 616us/step\n",
      "41/41 [==============================] - 0s 587us/step\n",
      "41/41 [==============================] - 0s 611us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "class PredictCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (epoch + 1) % SCHEDULER_STEP_SIZE == 0:\n",
    "            old_lr = self.model.optimizer.lr.numpy()\n",
    "            self.model.optimizer.learning_rate.assign(old_lr * GAMMA)\n",
    "        y_pred_val =  self.model.predict(X_test).tolist()\n",
    "        y_true_val =  self.y_test.tolist()\n",
    "        accuracy_r2 = round(r2_score(y_true_val, y_pred_val), 5)\n",
    "        hit, miss = 0, 0\n",
    "        for index, _ in enumerate(y_pred_val):\n",
    "            if round(y_pred_val[index][0]) == y_true_val[index]:\n",
    "                hit += 1\n",
    "            else:\n",
    "                miss += 1\n",
    "        basic_accuracy = hit / (hit + miss)\n",
    "        wandb.log({\n",
    "            'train_loss': logs['loss'],\n",
    "            'val_loss': logs['val_loss'],\n",
    "            'accuracy_r2': accuracy_r2,\n",
    "            'basic_accuracy': basic_accuracy\n",
    "        })\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=OPTIMIZER_FUNCT,\n",
    "    loss=LOSS_FUNC\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    verbose=0,\n",
    "    validation_data=(X_test, y_test),\n",
    "    validation_freq=1,\n",
    "    callbacks=[PredictCallback(X_test, y_test)]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do in the next week\n",
    "- Try 2 hidden layers\n",
    "- Try different number of neurons in hidden layers\n",
    "- Try different activation functions\n",
    "- Use validation data for tunning pytorch NN\n",
    "\n",
    "\n",
    "- validaciu musime volat v cykle po kazdej epoche, v cykle nastavovat net.val, net.train [X]\n",
    "- len testovaciu preprocesingovat [X]\n",
    "- learning rate treba dynamicky menit a dobre je to nastaviť na mensi [X]\n",
    "- spravit dobry shuffel [X]\n",
    "- wandb [X]\n",
    "- config [X]\n",
    "- accuracy riesit tak ze predikujeme napr 4.6, tak to zaokruhlime na 5 a pozrieme ci sme sa trafili povedal\n",
    "- asi neriesiť outliers\n",
    "- try other architecture (vacsi mode, sirsi model, inu aktivacnu funkciu)\n",
    "- TensorFlow implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsiete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8e0111090521f114717abe732992468edbc4fd14f83fb46be3e5df945a94075"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
