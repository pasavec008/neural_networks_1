{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>4188</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.048</td>\n",
       "      <td>25.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99045</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.62</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1224</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.033</td>\n",
       "      <td>29.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99080</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>4636</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.048</td>\n",
       "      <td>39.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.99212</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.566667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>2636</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.034</td>\n",
       "      <td>40.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.99773</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>4263</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>19.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.99269</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.46</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>3985</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.044</td>\n",
       "      <td>45.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.99454</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4480</th>\n",
       "      <td>610</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.083</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.99830</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>3827</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053</td>\n",
       "      <td>13.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.98956</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.39</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>4585</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.23</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.030</td>\n",
       "      <td>23.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.99322</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  fixed acidity  volatile acidity  citric acid  \\\n",
       "3687        4188            5.3              0.33         0.30   \n",
       "1070        1224            7.2              0.23         0.39   \n",
       "4101        4636            6.5              0.51         0.25   \n",
       "2289        2636            7.2              0.24         0.27   \n",
       "3756        4263            7.0              0.55         0.05   \n",
       "3505        3985            6.8              0.11         0.27   \n",
       "1              2            8.1              0.28         0.40   \n",
       "4480         610            8.8              0.24         0.54   \n",
       "3366        3827            5.1              0.23         0.18   \n",
       "4055        4585            5.0              0.33         0.23   \n",
       "\n",
       "      residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
       "3687             1.2      0.048                 25.0                 119.0   \n",
       "1070             2.3      0.033                 29.0                 102.0   \n",
       "4101             1.7      0.048                 39.0                 177.0   \n",
       "2289            11.4      0.034                 40.0                 174.0   \n",
       "3756             8.0      0.036                 19.0                 164.0   \n",
       "3505             8.6      0.044                 45.0                 104.0   \n",
       "1                6.9      0.050                 30.0                  97.0   \n",
       "4480             2.5      0.083                 25.0                  57.0   \n",
       "3366             1.0      0.053                 13.0                  99.0   \n",
       "4055            11.8      0.030                 23.0                 158.0   \n",
       "\n",
       "      density    pH  sulphates    alcohol  quality  color  \n",
       "3687  0.99045  3.32       0.62  11.300000        6      0  \n",
       "1070  0.99080  3.26       0.54  12.300000        7      0  \n",
       "4101  0.99212  3.28       0.57  10.566667        5      0  \n",
       "2289  0.99773  3.20       0.44   9.000000        5      0  \n",
       "3756  0.99269  3.26       0.46  12.200000        6      0  \n",
       "3505  0.99454  3.20       0.37   9.900000        6      0  \n",
       "1     0.99510  3.26       0.44  10.100000        6      0  \n",
       "4480  0.99830  3.39       0.54   9.200000        5      1  \n",
       "3366  0.98956  3.22       0.39  11.500000        5      0  \n",
       "4055  0.99322  3.41       0.64  11.800000        6      0  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/cleaned_data.csv', delimiter = ';')\n",
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac = 1, random_state=27)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df - 4907\n",
      "---------------\n",
      "train_df - 3140\n",
      "val_df - 785\n",
      "test_df - 982\n"
     ]
    }
   ],
   "source": [
    "# aj taketo riesenie existuje pip install sklearn\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "train_size = int(len(df) * 0.64)\n",
    "test_size = int(len(df) * 0.8)\n",
    "\n",
    "# training set - 64% from all data\n",
    "train_df = df[:train_size]\n",
    "\n",
    "# validation set - 16% from all data\n",
    "val_df = df[train_size:test_size]\n",
    "\n",
    "# testing set - 20% from all data\n",
    "test_df = df[test_size:]\n",
    "\n",
    "print('df -', df.shape[0])\n",
    "print('---------------')\n",
    "print('train_df -', train_df.shape[0])\n",
    "print('val_df -', val_df.shape[0])\n",
    "print('test_df -', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network architecture\n",
    "\n",
    "- Number of inputs for first layer is same as the number of attributes (columns) in our dataset\n",
    "- Number of outputs in last layer needs to be equal to the number of values that network is expected to predict. In our case we are trying to predict wine quality (range <3,9>)\n",
    "- The number of neurons (inputs and outputs) per layer in hidden layers can vary - we need to try different values to find better network performace. A good rule of thumb is to start with a smaller number of neurons and gradually increase the number of neurons until you find the optimal number that gives you the best performance.\n",
    "- We choose **ReLU as actiovation function**. In general, it works well\n",
    "- MSELoss (Mean squared error) is commonly use when you want to penalize larger errors more than smaller ones (common choise for regression problems)\n",
    "- We choose **SGD optimizer** because we have small dataset and problem with small complexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - epoch: 1 loss: 0.0029\n",
      "Training - epoch: 2 loss: 0.0026\n",
      "Training - epoch: 3 loss: 0.0022\n",
      "Training - epoch: 4 loss: 0.0018\n",
      "Training - epoch: 5 loss: 0.0016\n",
      "Training - epoch: 6 loss: 0.0014\n",
      "Training - epoch: 7 loss: 0.0013\n",
      "Training - epoch: 8 loss: 0.0012\n",
      "Training - epoch: 9 loss: 0.0012\n",
      "Training - epoch: 10 loss: 0.0011\n",
      "Validation - epoch: 10, loss: 0.1071\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.df.iloc[idx].values.astype('float32'))\n",
    "        y = torch.tensor(self.df.iloc[idx]['quality'].astype('float32'))\n",
    "        y_onehot = torch.zeros(7)\n",
    "        y_onehot[int(y) - 3] = 1.0\n",
    "        return x, y_onehot\n",
    "\n",
    "# Define your neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(14, 8)\n",
    "        self.fc2 = nn.Linear(8, 4)\n",
    "        self.fc3 = nn.Linear(4, 7)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.train()\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = MyDataset(train_df)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = MyDataset(val_df)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        # Labels shape and output shape must be same\n",
    "        # print(outputs.shape, labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print(f'Training - epoch: {epoch + 1} loss: {round(running_loss / 100, 4)}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Validation\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss = 0.0\n",
    "    for inputs, labels in val_dataloader:\n",
    "        outputs = net(inputs)\n",
    "        val_loss += criterion(outputs, labels).item()\n",
    "    print(f'Validation - epoch: {epoch + 1}, loss: {round(val_loss / len(val_dataloader), 4)}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do in the next week\n",
    "- Try 2 hidden layers\n",
    "- Try different number of neurons in hidden layers\n",
    "- Try different activation functions\n",
    "- Use validation data for tunning pytorch NN\n",
    "- TensorFlow implementation\n",
    "\n",
    "\n",
    "configs, wandb, try other orchitecture (vacsi mode, sirsi model, inu aktivacnu funkciu)\n",
    "regresiu, asi neriesiť outliers, accuracy riesit tak ze predikujeme napr 4.6, tak to zaokruhlime na 5 a pozrieme ci sme sa trafili\n",
    "povedal, ze nemusime mat validacny set\n",
    "- validaciu musime volat v cykle po kazdej epoche\n",
    "- len testovaciu preprocesingovat\n",
    "- learning rate treba dynamicky menit a dobre je to nastaviť na mensi\n",
    "- spravit dobry shuffel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsiete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8e0111090521f114717abe732992468edbc4fd14f83fb46be3e5df945a94075"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
