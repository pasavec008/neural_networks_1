{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1061</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.070</td>\n",
       "      <td>45.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>124</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.082</td>\n",
       "      <td>21.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99600</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>642</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.071</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99910</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>1772</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.059</td>\n",
       "      <td>32.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1043</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.48</td>\n",
       "      <td>19.45</td>\n",
       "      <td>0.048</td>\n",
       "      <td>55.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>4641</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.035</td>\n",
       "      <td>43.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.99094</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.63</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>133</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.035</td>\n",
       "      <td>46.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>944</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.051</td>\n",
       "      <td>16.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>891</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.031</td>\n",
       "      <td>40.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.99080</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.40</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>826</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.046</td>\n",
       "      <td>24.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.59</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  fixed acidity  volatile acidity  citric acid  \\\n",
       "1014        1061            7.0              0.21         0.28   \n",
       "4752         124            7.8              0.50         0.17   \n",
       "5106         642            9.9              0.54         0.45   \n",
       "1660        1772            7.8              0.40         0.26   \n",
       "997         1043            7.5              0.33         0.48   \n",
       "4404        4641            6.6              0.26         0.36   \n",
       "129          133            6.6              0.24         0.27   \n",
       "901          944            6.5              0.18         0.33   \n",
       "848          891            5.8              0.26         0.18   \n",
       "792          826            6.8              0.25         0.38   \n",
       "\n",
       "      residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
       "1014            7.50      0.070                 45.0                 185.0   \n",
       "4752            1.60      0.082                 21.0                 102.0   \n",
       "5106            2.30      0.071                 16.0                  40.0   \n",
       "1660            9.50      0.059                 32.0                 178.0   \n",
       "997            19.45      0.048                 55.0                 243.0   \n",
       "4404            1.20      0.035                 43.0                 126.0   \n",
       "129            15.80      0.035                 46.0                 188.0   \n",
       "901             8.00      0.051                 16.0                 131.0   \n",
       "848             1.20      0.031                 40.0                 114.0   \n",
       "792             8.10      0.046                 24.0                 155.0   \n",
       "\n",
       "      density    pH  sulphates  alcohol  quality  color  \n",
       "1014  0.99660  3.34       0.55      9.4        5      0  \n",
       "4752  0.99600  3.39       0.48      9.5        5      1  \n",
       "5106  0.99910  3.39       0.62      9.4        5      1  \n",
       "1660  0.99550  3.04       0.43     10.9        6      0  \n",
       "997   1.00100  2.95       0.40      8.8        5      0  \n",
       "4404  0.99094  3.01       0.63     11.4        6      0  \n",
       "129   0.99820  3.24       0.51      9.2        5      0  \n",
       "901   0.99650  3.28       0.44      8.7        7      0  \n",
       "848   0.99080  3.42       0.40     11.0        7      0  \n",
       "792   0.99560  3.33       0.59     10.2        6      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/cleaned_data.csv', delimiter = ';')\n",
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac = 1, random_state=27)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df - 5919\n",
      "---------------\n",
      "train_df - 3788\n",
      "val_df - 947\n",
      "test_df - 1184\n"
     ]
    }
   ],
   "source": [
    "# aj taketo riesenie existuje pip install sklearn\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "train_size = int(len(df) * 0.64)\n",
    "test_size = int(len(df) * 0.8)\n",
    "\n",
    "# training set - 64% from all data\n",
    "train_df = df[:train_size]\n",
    "\n",
    "# validation set - 16% from all data\n",
    "val_df = df[train_size:test_size]\n",
    "\n",
    "# testing set - 20% from all data\n",
    "test_df = df[test_size:]\n",
    "\n",
    "print('df -', df.shape[0])\n",
    "print('---------------')\n",
    "print('train_df -', train_df.shape[0])\n",
    "print('val_df -', val_df.shape[0])\n",
    "print('test_df -', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.587\n",
      "epoch: 2 loss: 0.0061\n",
      "epoch: 3 loss: 0.005\n",
      "epoch: 4 loss: 0.0055\n",
      "epoch: 5 loss: 0.0055\n",
      "epoch: 6 loss: 0.0052\n",
      "epoch: 7 loss: 0.0051\n",
      "epoch: 8 loss: 0.0055\n",
      "epoch: 9 loss: 0.0046\n",
      "epoch: 10 loss: 0.0051\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.df.iloc[idx].values.astype('float32'))\n",
    "        y = torch.tensor(self.df.iloc[idx]['color'].astype('float32'))\n",
    "        y_onehot = torch.zeros(2)\n",
    "        y_onehot[int(y)] = 1.0\n",
    "        return x, y_onehot\n",
    "\n",
    "# Define your neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(14, 8)\n",
    "        self.fc2 = nn.Linear(8, 4)\n",
    "        self.fc3 = nn.Linear(4, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.train()\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "batch_size = 64\n",
    "dataset = MyDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        # Labels shape and output shape must be same\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch: {epoch + 1} loss: {round(running_loss / 100, 4)}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsiete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8e0111090521f114717abe732992468edbc4fd14f83fb46be3e5df945a94075"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
